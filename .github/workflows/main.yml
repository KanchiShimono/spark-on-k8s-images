name: Build

on: [push, pull_request]

env:
  PYTHON_VERSION: 3.7.7
  SPARK_VERSION: 3.0.0
  HADOOP_VERSION: 3.2
  HADOOP_AWS_JAR_VERSION: 3.2.0
  AWS_JAVA_SDK_VERSION: 1.11.375
  SPARK_UID: 185
  IMAGE_OWNER: kanchishimono
  SPARK_IMAGE_NAME: spark
  PYSPARK_IMAGE_NAME: pyspark
  JUPYTER_IMAGE_NAME: pyspark-jupyter

jobs:
  build:
    name: Build and Push Docker image
    runs-on: ubuntu-latest
    steps:
      - name: Checkout the repository
        uses: actions/checkout@v2

      - name: Set metadata
        id: meta
        run: |
          SPARK_DOCKER_IMAGE="${IMAGE_OWNER}/${SPARK_IMAGE_NAME}"
          PYSPARK_DOCKER_IMAGE="${IMAGE_OWNER}/${PYSPARK_IMAGE_NAME}"
          JUPYTER_DOCKER_IMAGE="${IMAGE_OWNER}/${JUPYTER_IMAGE_NAME}"

          VERSION=noop

          if [[ $GITHUB_REF == refs/tags/* ]]; then
            VERSION=${GITHUB_REF#refs/tags/}
          elif [[ $GITHUB_REF == refs/heads/* ]]; then
            VERSION=$(echo ${GITHUB_REF#refs/heads/} | sed -r 's#/+#-#g')
          fi

          SPARK_TAGS="${SPARK_DOCKER_IMAGE}:${VERSION}"
          PYSPARK_TAGS="${PYSPARK_DOCKER_IMAGE}:${VERSION}"
          JUPYTER_TAGS="${JUPYTER_DOCKER_IMAGE}:${VERSION}"

          if [[ $VERSION =~ ^v[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
            MINOR=${VERSION%.*}
            MAJOR=${MINOR%.*}
            SPARK_TAGS="$SPARK_TAGS,${SPARK_DOCKER_IMAGE}:${MINOR},${SPARK_DOCKER_IMAGE}:${MAJOR},${SPARK_DOCKER_IMAGE}:latest"
            PYSPARK_TAGS="$PYSPARK_TAGS,${PYSPARK_DOCKER_IMAGE}:${MINOR},${PYSPARK_DOCKER_IMAGE}:${MAJOR},${PYSPARK_DOCKER_IMAGE}:latest"
            JUPYTER_TAGS="$JUPYTER_TAGS,${JUPYTER_DOCKER_IMAGE}:${MINOR},${JUPYTER_DOCKER_IMAGE}:${MAJOR},${JUPYTER_DOCKER_IMAGE}:latest"
          fi

          echo ::set-env name=VERSION::${VERSION}
          echo ::set-output name=spark_tags::${SPARK_TAGS}
          echo ::set-output name=pyspark_tags::${PYSPARK_TAGS}
          echo ::set-output name=jupyter_tags::${JUPYTER_TAGS}
          echo ::set-output name=created::$(date -u +'%Y-%m-%dT%H:%M:%SZ')

      - name: Download Spark
        working-directory: ./pyspark
        run: |
          wget https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
          tar xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
          mv spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} spark

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1

      - name: Build Spark Docker image by official tool
        working-directory: ./pyspark/spark
        run: |
          bin/docker-image-tool.sh -r spark -t ${VERSION} build

      - name: Build custom Spark Docker image for Spark on k8s
        uses: docker/build-push-action@v2
        with:
          context: ./spark
          build-args: |
            base=spark/spark:${{ env.VERSION }}
            spark_uid=${{ env.SPARK_UID }}
            HADOOP_AWS_JAR_VERSION=${{ env.HADOOP_AWS_JAR_VERSION }}
            AWS_JAVA_SDK_VERSION=${{ env.AWS_JAVA_SDK_VERSION }}
          load: true
          tags: ${{ steps.meta.outputs.spark_tags }}

      - name: Build PySpark Docker image
        uses: docker/build-push-action@v2
        with:
          context: ./pyspark
          build-args: |
            base=spark/spark:${{ env.VERSION }}
            spark_uid=${{ env.SPARK_UID }}
            python_version=${{ env.PYTHON_VERSION }}
          load: true
          tags: ${{ steps.meta.outputs.pyspark_tags }}

      - name: Build PySpark with Jupyter server Docker image
        uses: docker/build-push-action@v2
        with:
          context: ./pyspark-jupyter
          build-args: |
            base=${{ env.IMAGE_OWNER }}/${{ env.PYSPARK_IMAGE_NAME }}:${{ env.VERSION }}
            spark_uid=${{ env.SPARK_UID }}
          load: true
          tags: ${{ steps.meta.outputs.jupyter_tags }}

      - name: Login to DockerHub
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKERHUB_USER }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}
