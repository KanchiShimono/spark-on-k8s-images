name: Build

on:
  push:
    branches:
      - "**"
    tags:
      - "v*.*.*"
  pull_request:

env:
  PYTHON_VERSION: 3.8.5
  SPARK_VERSION: 3.0.0
  HADOOP_VERSION: 3.2
  HADOOP_AWS_JAR_VERSION: 3.2.0
  AWS_JAVA_SDK_VERSION: 1.11.375
  # set over 1000, if you want to create spark user as normal user (not system)
  SPARK_UID: 1850
  IMAGE_OWNER: ${{ secrets.DOCKERHUB_USER }}
  SPARK_IMAGE_NAME: spark
  PYSPARK_IMAGE_NAME: pyspark
  JUPYTER_IMAGE_NAME: pyspark-jupyter
  SPARK_GPU_IMAGE_NAME: spark-gpu
  PYSPARK_GPU_IMAGE_NAME: pyspark-gpu
  JUPYTER_GPU_IMAGE_NAME: pyspark-jupyter-gpu

jobs:
  build:
    name: Build and Push Docker image
    runs-on: ubuntu-latest
    steps:
      - name: Checkout the repository
        uses: actions/checkout@v2

      - name: Set container tags
        id: container-tags
        run: |
          TAGS=$(cat << EOF
            type=semver,priority=900,pattern={{raw}}
            type=semver,priority=900,pattern=v{{major}}
            type=semver,priority=900,pattern=v{{major}}.{{minor}}
            type=edge,priority=600
            type=ref,priority=500,event=pr
            type=ref,priority=700,event=branch
          EOF)
          TAGS="${TAGS//'%'/'%25'}"
          TAGS="${TAGS//$'\n'/'%0A'}"
          TAGS="${TAGS//$'\r'/'%0D'}"
          echo ::set-output name=tags::$TAGS

      - name: Docker meta Spark
        id: meta-spark
        uses: docker/metadata-action@v3
        with:
          images: ${{ env.IMAGE_OWNER }}/${{ env.SPARK_IMAGE_NAME }}
          tags: ${{ steps.container-tags.outputs.tags }}

      - name: Docker meta PySpark
        id: meta-pyspark
        uses: docker/metadata-action@v3
        with:
          images: ${{ env.IMAGE_OWNER }}/${{ env.PYSPARK_IMAGE_NAME }}
          tags: ${{ steps.container-tags.outputs.tags }}

      - name: Docker meta Jupyter
        id: meta-jupyter
        uses: docker/metadata-action@v3
        with:
          images: ${{ env.IMAGE_OWNER }}/${{ env.JUPYTER_IMAGE_NAME }}
          tags: ${{ steps.container-tags.outputs.tags }}

      - name: Docker meta Spark GPU
        id: meta-spark-gpu
        uses: docker/metadata-action@v3
        with:
          images: ${{ env.IMAGE_OWNER }}/${{ env.SPARK_GPU_IMAGE_NAME }}
          tags: ${{ steps.container-tags.outputs.tags }}

      - name: Docker meta PySpark GPU
        id: meta-pyspark-gpu
        uses: docker/metadata-action@v3
        with:
          images: ${{ env.IMAGE_OWNER }}/${{ env.PYSPARK_GPU_IMAGE_NAME }}
          tags: ${{ steps.container-tags.outputs.tags }}

      - name: Docker meta Jupyter GPU
        id: meta-jupyter-gpu
        uses: docker/metadata-action@v3
        with:
          images: ${{ env.IMAGE_OWNER }}/${{ env.JUPYTER_GPU_IMAGE_NAME }}
          tags: ${{ steps.container-tags.outputs.tags }}

      - name: Set create timestamp
        id: meta-create-timestamp
        run: |
          echo ::set-output name=created::$(date -u +'%Y-%m-%dT%H:%M:%SZ')

      - name: Download Spark
        working-directory: ./base-spark
        run: |
          wget https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
          tar xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
          mv spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} origin-spark

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
        with:
          driver: docker
          install: true

      - name: Build Ubuntu based Spark and PySpark image by official tool
        working-directory: ./base-spark
        run: >
          origin-spark/bin/docker-image-tool.sh
          -r spark
          -t ${{ steps.meta-spark.outputs.version }}
          -f Dockerfile
          -p bindings/python/Dockerfile
          -u ${SPARK_UID}
          build

      - name: Build custom Spark Docker image for Spark on k8s
        uses: docker/build-push-action@v2
        with:
          context: ./spark
          file: ./spark/Dockerfile
          build-args: |
            base=spark/spark:${{ steps.meta-spark.outputs.version }}
            spark_uid=${{ env.SPARK_UID }}
            HADOOP_AWS_JAR_VERSION=${{ env.HADOOP_AWS_JAR_VERSION }}
            AWS_JAVA_SDK_VERSION=${{ env.AWS_JAVA_SDK_VERSION }}
          load: true
          tags: ${{ steps.meta-spark.outputs.tags }}
          labels: |
            org.opencontainers.image.title=${{ env.SPARK_IMAGE_NAME }}
            org.opencontainers.image.description=${{ github.event.repository.description }}
            org.opencontainers.image.url=${{ github.event.repository.html_url }}
            org.opencontainers.image.source=${{ github.event.repository.clone_url }}
            org.opencontainers.image.version=${{ steps.meta-spark.outputs.version }}
            org.opencontainers.image.created=${{ steps.meta-create-timestamp.outputs.created }}
            org.opencontainers.image.revision=${{ github.sha }}

      - name: Build PySpark Docker image
        uses: docker/build-push-action@v2
        with:
          context: ./pyspark
          file: ./pyspark/Dockerfile
          build-args: |
            base=${{ env.IMAGE_OWNER }}/${{ env.SPARK_IMAGE_NAME }}:${{ steps.meta-spark.outputs.version }}
            base_pyspark=spark/spark-py:${{ steps.meta-spark.outputs.version }}
            spark_uid=${{ env.SPARK_UID }}
            python_version=${{ env.PYTHON_VERSION }}
          load: true
          tags: ${{ steps.meta-pyspark.outputs.tags }}
          labels: |
            org.opencontainers.image.title=${{ env.PYSPARK_IMAGE_NAME }}
            org.opencontainers.image.description=${{ github.event.repository.description }}
            org.opencontainers.image.url=${{ github.event.repository.html_url }}
            org.opencontainers.image.source=${{ github.event.repository.clone_url }}
            org.opencontainers.image.version=${{ steps.meta-pyspark.outputs.version }}
            org.opencontainers.image.created=${{ steps.meta-create-timestamp.outputs.created }}
            org.opencontainers.image.revision=${{ github.sha }}

      - name: Build PySpark with Jupyter server Docker image
        uses: docker/build-push-action@v2
        with:
          context: ./pyspark-jupyter
          file: ./pyspark-jupyter/Dockerfile
          build-args: |
            base=${{ env.IMAGE_OWNER }}/${{ env.PYSPARK_IMAGE_NAME }}:${{ steps.meta-pyspark.outputs.version }}
            spark_uid=${{ env.SPARK_UID }}
          load: true
          tags: ${{ steps.meta-jupyter.outputs.tags }}
          labels: |
            org.opencontainers.image.title=${{ env.JUPYTER_IMAGE_NAME }}
            org.opencontainers.image.description=${{ github.event.repository.description }}
            org.opencontainers.image.url=${{ github.event.repository.html_url }}
            org.opencontainers.image.source=${{ github.event.repository.clone_url }}
            org.opencontainers.image.version=${{ steps.meta-jupyter.outputs.version }}
            org.opencontainers.image.created=${{ steps.meta-create-timestamp.outputs.created }}
            org.opencontainers.image.revision=${{ github.sha }}

      - name: Build Spark GPU Docker image
        uses: docker/build-push-action@v2
        with:
          context: ./spark-gpu
          file: ./spark-gpu/Dockerfile
          build-args: |
            base=${{ env.IMAGE_OWNER }}/${{ env.SPARK_IMAGE_NAME }}:${{ steps.meta-spark.outputs.version }}
            spark_uid=${{ env.SPARK_UID }}
          load: true
          tags: ${{ steps.meta-spark-gpu.outputs.tags }}
          labels: |
            org.opencontainers.image.title=${{ env.SPARK_GPU_IMAGE_NAME }}
            org.opencontainers.image.description=${{ github.event.repository.description }}
            org.opencontainers.image.url=${{ github.event.repository.html_url }}
            org.opencontainers.image.source=${{ github.event.repository.clone_url }}
            org.opencontainers.image.version=${{ steps.meta-spark-gpu.outputs.version }}
            org.opencontainers.image.created=${{ steps.meta-create-timestamp.outputs.created }}
            org.opencontainers.image.revision=${{ github.sha }}

      - name: Build PySpark GPU Docker image
        uses: docker/build-push-action@v2
        with:
          context: ./pyspark
          file: ./pyspark/Dockerfile
          build-args: |
            base=${{ env.IMAGE_OWNER }}/${{ env.SPARK_GPU_IMAGE_NAME }}:${{ steps.meta-spark.outputs.version }}
            base_pyspark=spark/spark-py:${{ steps.meta-spark.outputs.version }}
            spark_uid=${{ env.SPARK_UID }}
            python_version=${{ env.PYTHON_VERSION }}
          load: true
          tags: ${{ steps.meta-pyspark-gpu.outputs.tags }}
          labels: |
            org.opencontainers.image.title=${{ env.PYSPARK_GPU_IMAGE_NAME }}
            org.opencontainers.image.description=${{ github.event.repository.description }}
            org.opencontainers.image.url=${{ github.event.repository.html_url }}
            org.opencontainers.image.source=${{ github.event.repository.clone_url }}
            org.opencontainers.image.version=${{ steps.meta-pyspark-gpu.outputs.version }}
            org.opencontainers.image.created=${{ steps.meta-create-timestamp.outputs.created }}
            org.opencontainers.image.revision=${{ github.sha }}

      - name: Build PySpark GPU with Jupyter server Docker image
        uses: docker/build-push-action@v2
        with:
          context: ./pyspark-jupyter
          file: ./pyspark-jupyter/Dockerfile
          build-args: |
            base=${{ env.IMAGE_OWNER }}/${{ env.PYSPARK_GPU_IMAGE_NAME }}:${{ steps.meta-pyspark-gpu.outputs.version }}
            spark_uid=${{ env.SPARK_UID }}
          load: true
          tags: ${{ steps.meta-jupyter-gpu.outputs.tags }}
          labels: |
            org.opencontainers.image.title=${{ env.JUPYTER_GPU_IMAGE_NAME }}
            org.opencontainers.image.description=${{ github.event.repository.description }}
            org.opencontainers.image.url=${{ github.event.repository.html_url }}
            org.opencontainers.image.source=${{ github.event.repository.clone_url }}
            org.opencontainers.image.version=${{ steps.meta-jupyter-gpu.outputs.version }}
            org.opencontainers.image.created=${{ steps.meta-create-timestamp.outputs.created }}
            org.opencontainers.image.revision=${{ github.sha }}

      - name: Login to DockerHub
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKERHUB_USER }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}

      - name: Push to DockerHub
        if: ${{ github.event_name != 'pull_request' }}
        env:
          SPARK_TAGS: ${{ steps.meta-spark.outputs.tags }}
          PYSPARK_TAGS: ${{ steps.meta-pyspark.outputs.tags }}
          JUPYTER_TAGS: ${{ steps.meta-jupyter.outputs.tags }}
          SPARK_GPU_TAGS: ${{ steps.meta-spark-gpu.outputs.tags }}
          PYSPARK_GPU_TAGS: ${{ steps.meta-pyspark-gpu.outputs.tags }}
          JUPYTER_GPU_TAGS: ${{ steps.meta-jupyter-gpu.outputs.tags }}
        run: |
          TAGS=$(\
            "${SPARK_TAGS//,/ }" \
            "${PYSPARK_TAGS//,/ }" \
            "${JUPYTER_TAGS//,/ }" \
            "${SPARK_GPU_TAGS//,/ }" \
            "${PYSPARK_GPU_TAGS//,/ }" \
            "${JUPYTER_GPU_TAGS//,/ }" \
          )
          for tag in ${TAGS[@]}; do
            docker push $tag
          done
